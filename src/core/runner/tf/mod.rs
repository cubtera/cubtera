use crate::prelude::*;

use std::collections::HashMap;
use std::io::Write;
use std::net::TcpListener;
use std::path::Path;
use std::process::Command;
use log::{info, warn, debug};
use rand::Rng;
use yansi::Paint;

mod tfswitch;
mod params;

use tfswitch::tf_switch;
use params::TfRunnerParams;
use super::{Runner, RunnerParams, RunnerContext};

pub struct TfRunner {
    ctx: RunnerContext,
    params: TfRunnerParams
}

// const LOCK_PORT: u16 = 65432;

impl Runner for TfRunner {
    fn new(ctx: RunnerContext) -> Self {
        let params = TfRunnerParams::init(ctx.params.clone());
        TfRunner {
            ctx,
            params
        }
    }

    fn init(&self) -> Result<(), Box<dyn std::error::Error>> {
        debug!(target: "tf runner", "Initialization process");

        self.copy_files()?;
        self.change_files()?;

        Ok(())
    }

    fn copy_files(&self) -> Result<(), Box<dyn std::error::Error>> {
        info!(target: "tf runner", "Copy files to: {}", &self.ctx.unit.temp_folder.to_string_lossy().blue());
        if self.ctx.command.first().unwrap_or(&"".into()).as_str() == "init"  {
            debug!(target: "tf runner", "Unit temp folder was created: \n{:?}", &self.ctx.unit.temp_folder);
            self.ctx.unit.remove_temp_folder();
            self.ctx.unit.copy_files();
        } else {
            if !self.ctx.unit.temp_folder.exists() {
                exit_with_error(format!(
                    "Can't find unit temp folder {:?}. Run init command first.",
                    &self.ctx.unit.temp_folder
                ));
            }
            if GLOBAL_CFG.always_copy_files {
                self.ctx.unit.copy_files();
            }
        }

        Ok(())
    }

    fn change_files(&self) -> Result<(), Box<dyn std::error::Error>> {
        debug!(target: "tf runner", "Change dimension data files into terraform format");

        // read all files started with dim_ and json extension
        let files = std::fs::read_dir(&self.ctx.unit.temp_folder)
            .unwrap_or_exit(format!("Can't read unit temp folder: {:?}", self.ctx.unit.temp_folder))
            .filter_map(|entry| entry.ok())
            .map(|entry| entry.path())
            .filter(|entry| entry.is_file())
            .filter(|entry| entry.extension().unwrap_or_default() == "json")
            // .filter(|entry| entry.file_stem().unwrap_or_default().to_str().unwrap_or_default().starts_with("dim_"))
            .filter(|entry| entry.file_stem().unwrap_or_default().to_str().unwrap_or_default().starts_with("cubtera_"))
            .filter(|entry| !entry.file_stem().unwrap_or_default().to_str().unwrap_or_default().contains(".auto.tfvars"))
            .collect::<Vec<std::path::PathBuf>>();

        // for each file read json as value and create list of root keys
        if !files.is_empty() {
            let dim_tf_variables: String = files.iter()
                .filter_map(|file| read_json_file(file))
                .filter_map(|json: serde_json::Value| json.as_object().map(|obj| obj.to_owned()))
                .flat_map(|obj| obj.into_iter().map(|(k, _)| k))
                .map(|key| format!(
r#"variable "{}" {{
    type        = any
    default     = null
    description = "Generated by Cubtera"
}}
"#,
                    key
                ))
                .collect();
            let mut file = std::fs::File::create(
                &self.ctx.unit.temp_folder.join("cubtera_vars.tf"))?;
            file.write_all(dim_tf_variables.as_bytes())?;
        }

        // if !self.unit.extensions.is_empty() {
        //     let mut ext_tf_vars = String::new();
        //     for extension in &self.unit.extensions {
        //         let mut ext = extension.split_terminator(':');
        //         ext_tf_vars.push_str(&format!(
        //             "variable \"ext_{}_name\" {{\n",
        //             ext.next().unwrap()
        //         ));
        //         ext_tf_vars.push_str(&format!("    default     = \"{}\"\n", ext.next().unwrap()));
        //         ext_tf_vars.push_str("    description = \"Generated by Cubtera\"\n");
        //         ext_tf_vars.push_str("}\n\n");
        //     }
        //     std::fs::write(&self.unit.temp_folder.join("ext_vars.tf"), ext_tf_vars)
        //         .unwrap_or_exit("Failed to write data into ext_vars.tf file".to_string());
        // }

        // rename all files to dim_<dim_name>.auto.tfvars.json
        files.iter().for_each(|file| {
            let new_file = file.with_file_name(
                format!("{}.auto.tfvars.json",
                    file.file_stem().unwrap_or_default().to_string_lossy() //.trim_start_matches("dim_")
                )
            );
            std::fs::rename(file, new_file).unwrap_or_exit(format!("Can't rename file: {:?}", file));
        });

        Ok(())
    }

    fn run(&self) -> Result<(), Box<dyn std::error::Error>> {
        let mut tf_args: Vec<String> = Vec::new();

        if let Some(command) = self.ctx.command.first() {
            match command.as_str() {
                "init" => {
                    tf_args.extend(self.tf_backend_conf_args());
                    debug!(target: "tf runner", "Unit temp folder was created: \n{:?}", &self.ctx.unit.temp_folder);
                }
                "plan" | "apply" | "destroy" | "refresh" => {
                    // check if unit temp folder is not empty
                    if !self.ctx.unit.temp_folder.exists() {
                        exit_with_error(format!(
                            "Can't find unit temp folder {:?}. Run init command first.",
                            &self.ctx.unit.temp_folder
                        ));
                    }
                    // extend vars with required env vars from unit manifest
                    tf_args.extend(self.tf_vars_args());
                }
                _ => {}
            }
        }

        // TODO: Remove legacy spec after units lib is fixed and remove params var usage
        let mut params = self.params.clone();
        if !self.ctx.unit.manifest.runner.is_some() {
            if let Some(spec) = &self.ctx.unit.manifest.spec {
                if let Some(version) = &spec.tf_version {
                    params.version = version.clone();
                    params.bin_path = None;
                    warn!(target: "tf runner", "{}: TF version is defined with {} in unit_manifest. \
                    Use {} instead.", "DEPRECATED".red(), "spec.tf_version".red(), "runner.version".blue());
                }
            }
        }

        let tf_path = match params.bin_path {
            Some(bin_path) => {
                info!(target: "tf runner", "Use custom binary path...");
                Path::new(&bin_path).to_path_buf()
            },
            None => {
                info!(target: "tf runner", "Run terraform version {}", &params.version.yellow());
                tf_switch(&params.version).unwrap_or_exit(format!(
                    "Failed to switch to terraform version {}", params.version))
            }
        };

        if let Some(extra_params) = &self.params.extra_params {
            tf_args.extend(extra_params.split(" ").map(|s| s.to_string()));
        }

        info!(target: "tf runner", "Command: {} {}",
            tf_path.to_string_lossy().blue(),
            self.ctx.command.join(" ").blue(),
        );

        let filtered_env_vars: HashMap<String, String> = std::env::vars()
            .filter(
                |(k, _)| k.starts_with("TF_VAR_"), //|| k == "CUBTERA_TF_STATE_BUCKET_NAME"
            )
            .collect();

        // start terraform with all required arguments
        let mut tf_command = Command::new(&tf_path);

        let mut socket: Option<TcpListener> = None;
        // check if another instance is running with init and wait for it to finish
        if matches!(&self.ctx.command.as_slice(), [cmd, ..] if cmd == "init") {
            let delay = rand::thread_rng().gen_range(800..1200);

            // while socket.is_none() {
            //     socket = TcpListener::bind(("0.0.0.0", LOCK_PORT)).ok();
            //     info!(target: "tf runner", "Waiting for unlock while init in parallel");
            //     std::thread::sleep(std::time::Duration::from_millis(delay));
            // }

            loop {
                match TcpListener::bind(("0.0.0.0", self.params.get_lock_port())) {
                    Ok(listener) => {
                        socket = Some(listener);
                        break;
                    }
                    Err(_) => {
                        info!(target: "tf runner", "Waiting for unlock while init in parallel");
                        std::thread::sleep(std::time::Duration::from_millis(delay));
                    }
                }
            }
        };

        debug!(target: "tf runner", "Additional args: {}", &tf_args.join(" ").blue());

        let mut child = tf_command
            .current_dir(self.ctx.unit.temp_folder.to_str().unwrap())
            .args(&self.ctx.command)
            .args(tf_args)
            .envs(filtered_env_vars)
            .env("TF_VAR_org_name", &GLOBAL_CFG.org)
            .env("TF_VAR_tf_state_s3bucket", &GLOBAL_CFG.tf_state_s3bucket)
            .env("TF_VAR_tf_state_s3region", &GLOBAL_CFG.tf_state_s3region)
            .env(
                "TF_VAR_tf_state_key_prefix",
                &GLOBAL_CFG.tf_state_key_prefix.clone().unwrap_or_default(),
            )
            //.env("TF_DATA_DIR", &self.config.temp_folder_path)
            //.env("TF_PLUGIN_CACHE_DIR", "~/.terraform.d/plugin-cache")
            //.env("TF_DATA_DIR", &self.config.temp_folder_path)
            //.env("TF_CLI_ARGS", "-compact-warnings")
            // TODO: implement different exit status configuration only for apply and plan commands:
            //.env("TF_CLI_ARGS","-detailed-exitcode")
            .env("TF_IN_AUTOMATION", "true")
            .env("TF_INPUT", "0")
            .spawn()
            .unwrap_or_exit(format!(
                "Failed to start {:?} with args {:?}",
                tf_path, &self.ctx.command
            ));

        let result = child
            .wait()
            .unwrap_or_exit("Failed to get terraform exitcode".to_string());

        let exit_code = result.code().unwrap_or(1);

        let tf_command = GLOBAL_CFG.dlog_db.clone()
            .and(matches!(self.ctx.command.as_slice(), [cmd, ..] if cmd == "apply")
                .then_some("apply")
                .or(matches!(self.ctx.command.as_slice(), [cmd, ..] if cmd == "destroy")
                    .then_some("destroy")));

        if let Some(tf_command) = tf_command {
            let dlog = Dlog::build(
                self.ctx.unit.clone(),
                tf_command.into(),
                exit_code,
            );
            let _ = dlog.put(&GLOBAL_CFG.org).check_with_warn("Can't put dlog to DB");
            info!(target: "tf runner", "Dlog data was saved");
        }

        if socket.is_some() {
            debug!(target: "tf runner", "Unlocking parallel run after finishing init command");
            drop(socket);
        }

        if !GLOBAL_CFG.clean_cache {
            debug!(target: "tf runner", "Ignore cache cleaning due to global config");
            std::process::exit(exit_code);
        }

        if exit_code == 0 {
            if let Some(first_command) = self.ctx.command.first() {
                if first_command == "apply"
                    || self.ctx.command.contains(&"--detailed-exitcode".to_owned())
                {
                    debug!(target: "tf runner", "Remove temp folder after successful {} command", "apply".blue());
                    self.ctx.unit.remove_temp_folder();
                }
            }
        }

        std::process::exit(exit_code);
    }
}

impl TfRunner {
    fn tf_vars_args(&self) -> Vec<String> {
        let mut tf_vars_args: Vec<String> = Vec::new();
        // extend vars with required env vars from unit manifest
        if let Some(spec) = &self.ctx.unit.manifest.spec {
            if let Some(env_vars) = &spec.env_vars {
                if let Some(required) = &env_vars.required {
                    for var in required {
                        tf_vars_args.extend([
                            "-var".to_string(),
                            format!(
                                "{}={}",
                                var.0,
                                std::env::var(var.1).unwrap_or_exit(format!("Required {}", var.1))
                            ),
                        ]);
                    }
                };
                if let Some(optional) = &env_vars.optional {
                    for var in optional {
                        if let Ok(env_var_value) = std::env::var(var.1) {
                            tf_vars_args
                                .extend(["-var".to_string(), format!("{}={env_var_value}", var.0)]);
                        }
                    }
                }
            }
        }

        tf_vars_args
    }

    fn tf_backend_conf_args(&self) -> Vec<String> {
        let unit_state_path = format!(
            "{}{}/{}.tfstate",
            GLOBAL_CFG.tf_state_key_prefix.clone().unwrap_or_default(),
            self.ctx.unit.get_unit_state_path(),
            self.ctx.unit.name
        );

        debug!(target: "tf runner", "Unit state path: \n{:?}", unit_state_path);
        debug!(target: "tf runner", "Unit state bucket: {}", GLOBAL_CFG.tf_state_s3bucket);

        let local_state_path = "~/.cubtera".replace('~', &std::env::var("HOME").unwrap_or_default());
        if GLOBAL_CFG.tf_state_s3bucket.is_empty() || &self.params.state_backend == "local" {
            [
                "-backend-config".to_string(),
                format!("path={}/state/{}", local_state_path, unit_state_path),
            ].to_vec()
        }
        else {
            [
                "-backend-config".to_string(),
                format!("key={}", unit_state_path),
                "-backend-config".to_string(),
                format!("bucket={}", GLOBAL_CFG.tf_state_s3bucket),
                "-backend-config".to_string(),
                format!("region={}", GLOBAL_CFG.tf_state_s3region),
                // "-backend-config".to_string(),
                // format!("dynamodb_table=tf-state-lock"),
                //TODO: implement DynamoDB lock configuration
            ].to_vec()
        }
    }
}